{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRE  writing pool generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWcu83OJQKbQ",
        "colab_type": "text"
      },
      "source": [
        "# Generate Your GRE Writing Pool file\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1tSlVHUwtCfOktzJI--3hWnWs2JML7qXi?usp=sharing)\n",
        "\n",
        "Link to the Github repository: [https://github.com/ktxlh/gre-writing-pool-scraper](https://github.com/ktxlh/gre-writing-pool-scraper)\n",
        "\n",
        "Run these cells to create your own GRE writing pool with indexes directly from the official website.\n",
        "\n",
        "Your task: Run all 3 cells by clicking the \"run\" buttons to the left of each one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po1C1Mo8gABi",
        "colab_type": "text"
      },
      "source": [
        "## 1. Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAsh2qT7PBOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Name your output files\n",
        "argument_pool_file_name = \"Argument pool.txt\" #@param {type:\"string\"}\n",
        "issue_pool_file_name = \"Issue pool.txt\" #@param {type:\"string\"}\n",
        "\n",
        "# Where to access the pool\n",
        "argument_url = \"https://www.ets.org/gre/revised_general/prepare/analytical_writing/argument/pool\" #@param {type:\"string\"} \n",
        "issue_url = \"https://www.ets.org/gre/revised_general/prepare/analytical_writing/issue/pool\" #@param {type:\"string\"} \n",
        "\n",
        "# Prompt indexes start from 1\n",
        "start_index = 1 #@param {type:\"integer\"}\n",
        "\n",
        "# Separation symbol(s) between each pair of prompts\n",
        "# Default: Repeat \"-\" 122 times\n",
        "separation_symbol = \"-\" #@param {type:\"string\"}\n",
        "number_of_seperation_symbols = 122 #@param {type:\"integer\"}\n",
        "separation = separation_symbol * number_of_seperation_symbols\n",
        "\n",
        "# Starting words of last paragraph of each prompt\n",
        "promp_start_word = \"Write a response\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFbvFNKCSm-6",
        "colab_type": "text"
      },
      "source": [
        "## 2. Generate the Pools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AaMKPTygErP",
        "colab_type": "text"
      },
      "source": [
        "### Define modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htMlcnqUSyLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from requests import get\n",
        "from requests.exceptions import RequestException\n",
        "from contextlib import closing\n",
        "from bs4 import BeautifulSoup, element\n",
        "import datetime\n",
        "\n",
        "def is_good_response(resp):\n",
        "    \"\"\"\n",
        "    Returns True if the response seems to be HTML, False otherwise.\n",
        "    Ref: https://realpython.com/python-web-scraping-practical-introduction/\n",
        "    \"\"\"\n",
        "    content_type = resp.headers['Content-Type'].lower()\n",
        "    return (resp.status_code == 200 \n",
        "            and content_type is not None \n",
        "            and content_type.find('html') > -1)\n",
        "  \n",
        "\n",
        "def simple_get(url):\n",
        "    \"\"\"\n",
        "    Attempts to get the content at `url` by making an HTTP GET request.\n",
        "    If the content-type of response is some kind of HTML/XML, return the\n",
        "    text content, otherwise return None.\n",
        "    Ref: https://realpython.com/python-web-scraping-practical-introduction/\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with closing(get(url, stream=True)) as resp:\n",
        "            if is_good_response(resp):\n",
        "                return resp.content\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    except RequestException as e:\n",
        "        print('Error during requests to {0} : {1}'.format(url, str(e)))\n",
        "        return None\n",
        "\n",
        "\n",
        "def generate_pool(file_name, url):\n",
        "  raw_html = simple_get(url)\n",
        "  bs_html = BeautifulSoup(raw_html, 'html.parser')\n",
        "  ps = bs_html.select('div.contents.left')[0].select('p')\n",
        "\n",
        "  intro = ps[:2]\n",
        "  contents = ps[2:]\n",
        "  \n",
        "  i = start_index\n",
        "  lines = [p.text for p in list(contents)]\n",
        "  new_lines = []\n",
        "  new_lines.append(f\"# {i} \"+separation)\n",
        "\n",
        "  for line in lines:\n",
        "    new_lines.append(\"\\n\" + line)\n",
        "    if line.startswith(promp_start_word):\n",
        "      i += 1\n",
        "      new_lines.append(f\"\\n# {i} \"+separation)\n",
        "\n",
        "  with open(file_name, \"w\") as fout:\n",
        "    fout.write(file_name.split('.')[0] + \"\\n\")\n",
        "    fout.write(f\"{i-1} topics in total. Accessed on {datetime.date.today()}.\\n\\n\")\n",
        "    fout.write('\\n'.join(new_lines[:-1]) + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gWktNb6faqO",
        "colab_type": "text"
      },
      "source": [
        "### Generate files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng0HRhdYU6-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_pool(argument_pool_file_name, argument_url)\n",
        "generate_pool(issue_pool_file_name, issue_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y09EBMTpfdT3",
        "colab_type": "text"
      },
      "source": [
        "## 3. Obtain your pools\n",
        "There is a \"folder\" icon to the left of the window. Click it and hover your cursor to the two files with the name `Argument pool.txt` and `Issue pool.txt` or whatever you defined, click the 3 dots appeared and `Download` the file."
      ]
    }
  ]
}